{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ava-creates/decision_tree/blob/main/Decision_Tree_ID3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYoNncoEaL3y"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAc8pKiFaL3z"
      },
      "outputs": [],
      "source": [
        "# reading from the file using numpy genfromtxt with delimiter ','\n",
        "\n",
        "\n",
        "\n",
        "# normalize the entire dataset prior to learning using min-max normalization \n",
        "def normalize(data):\n",
        "    print(\"normalizing the entire dataset\")\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(data)\n",
        "    X = scaler.transform(data)\n",
        "    \n",
        "    return X\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heW1pQUDaL30"
      },
      "outputs": [],
      "source": [
        "# Class node and explanation is self explanation\n",
        "class Node(object):\n",
        "    \n",
        "    def __init__(self, level, leaf, label=None, attr=None, threshold=None):\n",
        "        self.attr = attr # attribute to split on\n",
        "        self.threshold = threshold # threshold of that attribute\n",
        "        self.level = level # level of this node in the tree\n",
        "        self.is_leaf = leaf\n",
        "        self.label = label ##\n",
        "        self.left_node = None\n",
        "        self.right_node = None\n",
        "\n",
        "    # method to identify if the node is leaf\n",
        "    def is_leaf(self):    \n",
        "        return self.is_leaf\n",
        "        \n",
        "    # method to return threshold value\n",
        "    def ret_theta(self):\n",
        "        return self.threshold\n",
        "    \n",
        "    # method return root value\n",
        "    def ret_attribute(self):\n",
        "        return self.attr\n",
        "    \n",
        "    # method return left tree\n",
        "    def ret_lnode(self):\n",
        "        return self.left_node\n",
        "\n",
        "    # method return right tree\n",
        "    def ret_rnode(self):\n",
        "        return self.right_node\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.is_leaf:\n",
        "            return \"(Label: %r)\" %(self.label)\n",
        "        else:\n",
        "            return \"(Attribute: %r, Theta: %r, Left: %r, Right: %r)\" % (self.attr, self.threshold, self.left_node, self.right_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F0fCHJsaL31"
      },
      "outputs": [],
      "source": [
        "class DecisionTree(object):\n",
        "    \n",
        "    def __init__(self, X):\n",
        "        self.root_node = None\n",
        "        self.features = [x for x in range(X.shape[1])] # features\n",
        "        print(\"New Decision Tree: Features--> \" , self.features)\n",
        "        self.used = [False for x in self.features] # whether the feature is used or not\n",
        "        \n",
        "        # stats of tree\n",
        "        self.node_count = 0\n",
        "        self.max_level = 0\n",
        "        self.leaf_count = 0\n",
        "       # self.verbose = verbose idk what it is\n",
        "    \n",
        "    def feature_depleted(self): \n",
        "        #check if all features have been used to build a tree\n",
        "        for i in self.used:\n",
        "          if(i==False):\n",
        "            return False\n",
        "        return True\n",
        "        \n",
        "    #fit function to start tree building process\n",
        "    def fit(self, X, y, n_min):\n",
        "        assert(X.shape[0] == y.shape[0])\n",
        "        self.root_node = self.create_decision_tree(X, y, n_min)\n",
        "        \n",
        "        print('Decision Tree built.')\n",
        "        print(\"Number of nodes:\", self.node_count)\n",
        "        print('Maximum depth:', self.max_level)\n",
        "        print('Leaf nodes count:', self.leaf_count)\n",
        "    \n",
        "    # Iterative Dichotomiser 3 algorithm        \n",
        "    def create_decision_tree(self, X, y, n_min, level = 0):\n",
        "        # increase number of nodes created\n",
        "        self.node_count += 1 \n",
        "\n",
        "        #calculate maximum level of tree to display on debug screen\n",
        "        self.max_level= math.floor(np.log2(self.node_count))\n",
        "\n",
        "        #calculate major class label and frequency to store as a predicted label\n",
        "        label, count = self.cal_major_class_values(y)\n",
        "\n",
        "        \n",
        "        \n",
        "        if self.feature_depleted() or X.shape[0] <= n_min or count == len(y):\n",
        "            # Stop splitting, when:\n",
        "            # 1. no more features to split, or\n",
        "            # 2. less samples in node than n_min, or\n",
        "            # 3. the node is pure.\n",
        "            \n",
        "            #create lead node with specific level number and increase leaf count\n",
        "\n",
        "            node = Node(level, True, label) #not sure what the label does in Node\n",
        "\n",
        "            self.leaf_count += 1\n",
        "            return node\n",
        "        \n",
        "        # find the best feature and threshold to split on\n",
        "        feature, threshold = self.best_feature(X, y)\n",
        "        \n",
        "        #if no best feature or threshold found stop splitting the tree and create a leaf node\n",
        "        if feature == -1 or threshold == -1:\n",
        "            \n",
        "            #create lead node with specific level number and increase leaf count\n",
        "            node=Node(level, True, label, feature, threshold)\n",
        "            \n",
        "            return node\n",
        "        \n",
        "        # otherwise continue splitting\n",
        "        \n",
        "        #mark feature as used \n",
        "        self.used[feature] =True\n",
        "        \n",
        "        #create subtree root (subtree_root, with specified split feature and threshold)\n",
        "        subtree_root = Node(level, False, label, feature, threshold)\n",
        "        \n",
        "        # split X, y for left and right subtree\n",
        "        left_X= []\n",
        "        right_X=[]\n",
        "        left_y=[]\n",
        "        right_y=[]\n",
        "        for i in range(0, X.shape[0]):\n",
        "          if(X[i, feature]<threshold):\n",
        "            left_X.append(X[i, :])\n",
        "            left_y.append(y[i])\n",
        "          else:\n",
        "            right_X.append(X[i, :])\n",
        "            right_y.append(y[i])\n",
        "\n",
        "        left_X=np.array(left_X)\n",
        "        right_X=np.array(right_X)\n",
        "        left_y=np.array(left_y)\n",
        "        right_y=np.array(right_y)\n",
        "     \n",
        "        assert(left_X.shape[0]!=0 and right_X.shape[0]!=0)\n",
        "        \n",
        "        # build three recursively\n",
        "        subtree_root.left_node = self.create_decision_tree(left_X, left_y, n_min, level + 1)\n",
        "        subtree_root.right_node = self.create_decision_tree(right_X, right_y, n_min, level + 1)\n",
        "        \n",
        "        return subtree_root\n",
        "        \n",
        "    # find the feature and threshold that gives the most entropy gain\n",
        "    def best_feature(self, X, y):\n",
        "        best_gain = 10000000000000000000000000000000\n",
        "        best_fea, threshold = -1, -1\n",
        "        for i in range(0,len(self.features)):\n",
        "            if(self.used[i]==False):\n",
        "             thresholds = np.unique(X[:, i])\n",
        "             for t in thresholds:\n",
        "                gain = 0\n",
        "               # parent_entropy =self.entropy(y)\n",
        "                left_X= []\n",
        "                right_X=[]\n",
        "                left_y=[]\n",
        "                right_y=[]\n",
        "                for j in range(0, X.shape[0]):\n",
        "                  if(X[j, i]<t):\n",
        "                    left_X.append(X[j,:])\n",
        "                    left_y.append(y[j])\n",
        "                  else:\n",
        "                    right_X.append(X[j, :])\n",
        "                    right_y.append(y[j])\n",
        "\n",
        "                left_X=np.array(left_X)\n",
        "                right_X=np.array(right_X)\n",
        "                left_y=np.array(left_y)\n",
        "                right_y=np.array(right_y)\n",
        "\n",
        "                n=len(y)\n",
        "                ll=len(left_y)\n",
        "                lr= len(right_y)\n",
        "                enl= self.entropy(left_y)\n",
        "                enr= self.entropy(right_y)\n",
        "                children_entropy=(ll / n) * enl + (lr / n) * enr\n",
        "\n",
        "                gain= children_entropy\n",
        "                if(gain<best_gain):\n",
        "                  best_gain=gain\n",
        "                  best_fea=i\n",
        "                  threshold=t\n",
        "\n",
        "\n",
        "      \n",
        "        return best_fea, threshold\n",
        "                \n",
        "    \n",
        "    # find the dominant label in the node\n",
        "    def cal_major_class_values(self, y):\n",
        "\n",
        "        labels= np.unique(y)\n",
        "        a=[]\n",
        "\n",
        "        \n",
        "        for i in labels:\n",
        "          a.append(0)\n",
        "        \n",
        "        for i in range(0, y.shape[0]):\n",
        "          for j in range(0 , labels.shape[0]):\n",
        "            if(y[i]==labels[j]):\n",
        "              a[j]+=1\n",
        "        \n",
        "        b=max(a)\n",
        "        count=b\n",
        "        dominant_label=-1\n",
        "       \n",
        "        for i in range(0, len(a)):\n",
        "          if(a[i]==b):\n",
        "            dominant_label= labels[i]\n",
        "            break\n",
        "\n",
        "        return dominant_label, count            \n",
        "            \n",
        "    # entropy calculation\n",
        "    def entropy(self, y):\n",
        "        y_ = y.astype(int)\n",
        "        a = np.bincount(y_)\n",
        "        b= a/len(y_)\n",
        "        entropy= 0\n",
        "\n",
        "        for i in b:\n",
        "          if(i>0):\n",
        "           entropy+= i*np.log2(i)\n",
        "\n",
        "\n",
        "        return -1*entropy\n",
        "    \n",
        "    def predict(self, X):\n",
        "        predicted = []\n",
        "            #predict label for each example in input X starting from the root node\n",
        "        for i in range(0,  X.shape[0]):\n",
        "          node= self.root_node\n",
        "          while (node.is_leaf==False):\n",
        "            if(X[i, node.attr]<node.ret_theta()):\n",
        "              node=node.ret_lnode()\n",
        "            else:\n",
        "              node= node.ret_rnode()\n",
        "\n",
        "          predicted.append(node.label)\n",
        "         \n",
        "        return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD6BpfBQaL34"
      },
      "outputs": [],
      "source": [
        "#calculating the predicited accuracy\n",
        "def accuracy(actual,predicted):\n",
        "    right=0\n",
        "    \n",
        "    for i in range(0, len(predicted)):\n",
        "      if(actual[i]==predicted[i]):\n",
        "        right+=1\n",
        "\n",
        "    accuracy= (right/len(predicted))\n",
        "\n",
        "\n",
        "\n",
        "    # return the accuracy\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W7BKYJzaL34"
      },
      "outputs": [],
      "source": [
        "def main(X, y, eta_min):\n",
        "    #specify early termination criteria\n",
        "    eta_min_val = round(eta_min*X.shape[0])\n",
        "    \n",
        "    #Normalize input data X\n",
        "    X = normalize(X)\n",
        "\n",
        "    total= []\n",
        "    \n",
        "    #generate 10 folds split on data\n",
        "    kf = KFold(n_splits=10,shuffle=True, random_state=np.random.randint(10,21))\n",
        "    \n",
        "    for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_train, X_test=X[train_index], X[test_index]\n",
        "        y_train, y_test=y[train_index], y[test_index]\n",
        "        tree= DecisionTree(X)\n",
        "        tree.fit( X_train, y_train, eta_min_val)\n",
        "        predicted=tree.predict(X_test)\n",
        "        accu=accuracy(y_test, predicted)\n",
        "        total.append(accu)\n",
        "        \n",
        "        #for each training and test fold build a decision tree and report accuracy\n",
        "\n",
        "        print(\"Accuracy is \",accu)\n",
        "    \n",
        "    total=np.array(total)\n",
        "    #print mean accuracy \n",
        "    mean =(np.sum(total)/10)\n",
        "\n",
        "    sd= (np.std(total))\n",
        "    #return mean accuracy of 10 folds and report standard deviation\n",
        "    return  mean, sd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4ClEGDCaL35"
      },
      "source": [
        "# Test on Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgOAFGZJaL37",
        "outputId": "e47788e0-ca98-4bfa-e110-2043b53ed869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalizing the entire dataset\n",
            "[[0.22222222 0.625      0.06779661 0.04166667]\n",
            " [0.16666667 0.41666667 0.06779661 0.04166667]\n",
            " [0.11111111 0.5        0.05084746 0.04166667]\n",
            " [0.08333333 0.45833333 0.08474576 0.04166667]\n",
            " [0.19444444 0.66666667 0.06779661 0.04166667]\n",
            " [0.30555556 0.79166667 0.11864407 0.125     ]\n",
            " [0.08333333 0.58333333 0.06779661 0.08333333]\n",
            " [0.19444444 0.58333333 0.08474576 0.04166667]\n",
            " [0.02777778 0.375      0.06779661 0.04166667]\n",
            " [0.16666667 0.45833333 0.08474576 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # To read in the dataset we will use the Panda's library\n",
        "df = pd.read_csv('./sample_data/Iris.csv', header=None, names =\n",
        "                 [\"sepal length[cm]\",\"sepal width[cm]\",\"petal length[cm]\", \"petal width\", \"label\"])\n",
        "df['label'] = df.label.map({'Iris-setosa': 0,\n",
        "              'Iris-versicolor': 1,\n",
        "              'Iris-virginica': 2})\n",
        "X = df.values\n",
        "\n",
        "y = X[1:,-1]\n",
        "X = X[1:,:-1]\n",
        "X=normalize(X)\n",
        "print(X[0:10,:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPzdVjkHaL38"
      },
      "outputs": [],
      "source": [
        "#testing with different early stopage criteria\n",
        "eta_min_list = [.01, 0.05,0.10,0.15,0.20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BJM6cAfaL38",
        "outputId": "8871450d-6b62-482d-d9c5-e7d4e9d4c7ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8666666666666667\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8666666666666667\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "----------------------------------------------------------------------------------\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8666666666666667\n",
            "----------------------------------------------------------------------------------\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "----------------------------------------------------------------------------------\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8666666666666667\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8666666666666667\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "----------------------------------------------------------------------------------\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8666666666666667\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 7\n",
            "Maximum depth: 2\n",
            "Leaf nodes count: 4\n",
            "Accuracy is  0.8666666666666667\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.9333333333333333\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.8666666666666667\n",
            "----------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(columns=['Eta min', 'Mean Accuracy', 'Sd'])\n",
        "for i in eta_min_list:\n",
        "    accu, std = main(X, y, i)\n",
        "    print(\"----------------------------------------------------------------------------------\")\n",
        "    df = df.append({'Eta min': i, 'Mean Accuracy': accu, 'Sd': std}, ignore_index=True, sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WzL4FdraL39"
      },
      "source": [
        "### The result is summarized in the following table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TlU-k0ReXJCp",
        "outputId": "94d60300-f657-46af-c461-16383b8da19c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-26d1d457-7be9-4927-8f02-19c72f728b7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Eta min</th>\n",
              "      <th>Mean Accuracy</th>\n",
              "      <th>Sd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.046667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.946667</td>\n",
              "      <td>0.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.055377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.046667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.055377</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26d1d457-7be9-4927-8f02-19c72f728b7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26d1d457-7be9-4927-8f02-19c72f728b7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26d1d457-7be9-4927-8f02-19c72f728b7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Eta min  Mean Accuracy        Sd\n",
              "0     0.01       0.940000  0.046667\n",
              "1     0.05       0.946667  0.040000\n",
              "2     0.10       0.940000  0.055377\n",
              "3     0.15       0.940000  0.046667\n",
              "4     0.20       0.940000  0.055377"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul4URHp_aL39"
      },
      "source": [
        "# Test on spam email dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS3uJHTUaL3-"
      },
      "outputs": [],
      "source": [
        "eta_min_list = [0.05,0.10,0.15,0.20,0.25]\n",
        "#eta_min_list = [0.75]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOHc6iZaL3-",
        "outputId": "ba705db5-5116-40eb-bc7f-34a0156a5ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalizing the entire dataset\n",
            "[[4.62555066e-02 1.96078431e-02 9.80392157e-02 0.00000000e+00\n",
            "  1.40000000e-02 4.76190476e-02 2.88858322e-02 6.30063006e-03\n",
            "  0.00000000e+00 5.17051705e-02 8.04597701e-02 8.16959669e-02\n",
            "  1.17117117e-01 2.10000000e-02 3.17460317e-02 7.00000000e-03\n",
            "  9.80392157e-03 3.08030803e-02 1.85066667e-01 0.00000000e+00\n",
            "  1.43114311e-01 0.00000000e+00 7.88990826e-02 3.44000000e-02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.01596517e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.35356850e-02 0.00000000e+00 1.14539073e-02\n",
            "  2.99850075e-02 2.42069696e-03 3.73490695e-03 1.00120144e-02\n",
            "  6.48358586e-02]\n",
            " [1.32158590e-02 0.00000000e+00 1.39215686e-01 0.00000000e+00\n",
            "  1.23000000e-01 3.23129252e-02 2.61348006e-02 1.08010801e-02\n",
            "  1.21673004e-01 1.37513751e-02 1.45593870e-01 4.65356774e-02\n",
            "  2.16216216e-02 0.00000000e+00 3.96825397e-01 3.00000000e-03\n",
            "  8.40336134e-03 1.13311331e-01 7.25333333e-02 1.76017602e-02\n",
            "  4.59045905e-02 0.00000000e+00 2.12844037e-01 4.80000000e-03\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.26050420e-02\n",
            "  0.00000000e+00 0.00000000e+00 3.36134454e-02 0.00000000e+00\n",
            "  2.80112045e-03 2.72108844e-03 0.00000000e+00 0.00000000e+00\n",
            "  2.28050171e-03 1.46636587e-02 0.00000000e+00 8.49806023e-03\n",
            "  3.06513410e-02 5.04311866e-04 8.00817068e-03 4.84581498e-02\n",
            "  1.42550505e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  6.30000000e-02 0.00000000e+00 4.26409904e-02 5.67056706e-02\n",
            "  5.89353612e-02 3.46534653e-02 1.18773946e-01 3.20579111e-02\n",
            "  5.58558559e-02 0.00000000e+00 0.00000000e+00 1.55000000e-02\n",
            "  0.00000000e+00 0.00000000e+00 1.69600000e-01 0.00000000e+00\n",
            "  2.79027903e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.40484003e-02 0.00000000e+00 4.21824004e-03\n",
            "  0.00000000e+00 0.00000000e+00 2.30322288e-03 3.90468562e-03\n",
            "  1.19949495e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  6.30000000e-02 0.00000000e+00 4.26409904e-02 5.67056706e-02\n",
            "  5.89353612e-02 3.46534653e-02 1.18773946e-01 3.20579111e-02\n",
            "  5.58558559e-02 0.00000000e+00 0.00000000e+00 1.55000000e-02\n",
            "  0.00000000e+00 0.00000000e+00 1.69600000e-01 0.00000000e+00\n",
            "  2.79027903e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.38433142e-02 0.00000000e+00 4.15665989e-03\n",
            "  0.00000000e+00 0.00000000e+00 2.30322288e-03 3.90468562e-03\n",
            "  1.19949495e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.85000000e-01 0.00000000e+00 0.00000000e+00 1.66516652e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 2.28671042e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.81570586e-03 1.40168202e-03\n",
            "  3.34595960e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.92000000e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 3.52035204e-02 3.67816092e-01 1.32368149e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e-02\n",
            "  0.00000000e+00 3.52035204e-02 2.05333333e-01 0.00000000e+00\n",
            "  5.76057606e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 5.53732568e-03 0.00000000e+00 5.04957202e-03\n",
            "  8.99550225e-03 0.00000000e+00 6.09169315e-04 3.00360433e-04\n",
            "  7.00757576e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.88000000e-01 0.00000000e+00 0.00000000e+00 1.69216922e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 2.11238720e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.31638675e-03 1.00120144e-03\n",
            "  3.03030303e-03]\n",
            " [3.30396476e-02 0.00000000e+00 9.01960784e-02 0.00000000e+00\n",
            "  6.10000000e-02 0.00000000e+00 4.12654746e-02 0.00000000e+00\n",
            "  1.74904943e-01 4.18041804e-02 2.91187739e-01 9.51396070e-02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.65016502e-02 6.56000000e-02 1.94169417e-01\n",
            "  1.80018002e-01 0.00000000e+00 0.00000000e+00 1.20000000e-02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  8.25082508e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 8.40336134e-02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 2.77891715e-02 0.00000000e+00 5.57300326e-03\n",
            "  3.38164251e-02 1.10948611e-03 7.93826600e-03 4.44533440e-02\n",
            "  7.92929293e-02]\n",
            " [1.32158590e-02 8.40336134e-03 1.50980392e-01 0.00000000e+00\n",
            "  1.90000000e-02 5.44217687e-02 5.22696011e-02 0.00000000e+00\n",
            "  1.14068441e-02 0.00000000e+00 0.00000000e+00 6.61840745e-02\n",
            "  4.50450450e-02 0.00000000e+00 2.72108844e-02 0.00000000e+00\n",
            "  0.00000000e+00 1.32013201e-02 8.90666667e-02 3.30033003e-03\n",
            "  6.39063906e-02 0.00000000e+00 3.48623853e-02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.00000000e-03\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  9.12200684e-03 3.07629204e-03 0.00000000e+00 7.51277788e-03\n",
            "  1.34932534e-02 0.00000000e+00 6.61824784e-04 4.20504606e-03\n",
            "  4.72222222e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.32049519e-01 0.00000000e+00\n",
            "  0.00000000e+00 1.05610561e-01 3.67816092e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.05610561e-01 2.04800000e-01 0.00000000e+00\n",
            "  8.64086409e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.01680672e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.42250139e-02\n",
            "  0.00000000e+00 0.00000000e+00 2.83250113e-04 5.00600721e-04\n",
            "  1.26262626e-03]]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/spambase.csv')\n",
        "                 \n",
        "X = df.values\n",
        "\n",
        "y = X[:,-1]\n",
        "X = X[:,:-1]\n",
        "X=normalize(X)\n",
        "print(X[0:10,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-cNm0sDaL3-",
        "outputId": "7bd52c61-3ea7-4832-d135-286ac7e6fb76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 25\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 13\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 29\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 15\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 25\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 13\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 21\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 11\n",
            "Accuracy is  0.95\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 27\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 14\n",
            "Accuracy is  0.75\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 25\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 13\n",
            "Accuracy is  0.95\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 25\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 13\n",
            "Accuracy is  0.75\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 25\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 13\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 27\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 14\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 21\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 11\n",
            "Accuracy is  0.9\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 19\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 10\n",
            "Accuracy is  0.9\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 19\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 10\n",
            "Accuracy is  0.75\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 23\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 12\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 25\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 13\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 19\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 10\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 21\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 11\n",
            "Accuracy is  1.0\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 19\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 10\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.9\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.95\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.95\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 23\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 12\n",
            "Accuracy is  0.75\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 11\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 6\n",
            "Accuracy is  0.7\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 13\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 7\n",
            "Accuracy is  0.75\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 13\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 7\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.9\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.9\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.85\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 11\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 6\n",
            "Accuracy is  0.75\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 17\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 9\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 13\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 7\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 11\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 6\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 11\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 6\n",
            "Accuracy is  0.8\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.9\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.95\n",
            "normalizing the entire dataset\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 11\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 6\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.9\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 19\n",
            "Maximum depth: 4\n",
            "Leaf nodes count: 10\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.7\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.95\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 9\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 5\n",
            "Accuracy is  0.75\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 11\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 6\n",
            "Accuracy is  0.85\n",
            "New Decision Tree: Features-->  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
            "Decision Tree built.\n",
            "Number of nodes: 15\n",
            "Maximum depth: 3\n",
            "Leaf nodes count: 8\n",
            "Accuracy is  0.95\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y)\n",
        "X=X[0:200, :]\n",
        "y=y[0:200]\n",
        "df = pd.DataFrame(columns=['Eta min', 'Mean Accuracy', 'Sd'])\n",
        "for i in eta_min_list:\n",
        "    #running for 200 rows as it is too big\n",
        "    accu, std = main(X, y, i)\n",
        "    df = df.append({'Eta min': i, 'Mean Accuracy': accu, 'Sd': std}, ignore_index=True, sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yZwE6t2CaL3-",
        "outputId": "b3db4d61-e0f5-452d-a338-f66f55e9f21b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-667a55e9-ea95-4440-897e-bde40810c85e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Eta min</th>\n",
              "      <th>Mean Accuracy</th>\n",
              "      <th>Sd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.070887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.067082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.845</td>\n",
              "      <td>0.082006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.840</td>\n",
              "      <td>0.053852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.074162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-667a55e9-ea95-4440-897e-bde40810c85e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-667a55e9-ea95-4440-897e-bde40810c85e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-667a55e9-ea95-4440-897e-bde40810c85e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Eta min  Mean Accuracy        Sd\n",
              "0     0.05          0.835  0.070887\n",
              "1     0.10          0.850  0.067082\n",
              "2     0.15          0.845  0.082006\n",
              "3     0.20          0.840  0.053852\n",
              "4     0.25          0.850  0.074162"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qq4dikbkaL3-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Decision_Tree_ID3_.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}